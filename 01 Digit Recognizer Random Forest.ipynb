{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminaries\n",
    "Add the necessary libraries and create Spark Context and create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "import time\n",
    "\n",
    "sc = SparkContext(appName=\"MNISTDigitsDT\")\n",
    "fileNameTrain = 'wasb://datasets@chuvyrov.blob.core.windows.net/trainingsample.csv'\n",
    "fileNameTest = 'wasb://datasets@chuvyrov.blob.core.windows.net/validationsample.csv'\n",
    "\n",
    "mnist_train = sc.textFile(fileNameTrain)\n",
    "mnist_test = sc.textFile(fileNameTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to parse CSV lines and convert them to LabeledPoint. LabeledPoint is the class that our Machine Learning algorithms expects (down below). Note the additional values we are extracting from the data - 'gender' and 'embarked.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    \"\"\"\n",
    "    Parse a line of text into a set of MLlib LabeledPoint object.\n",
    "    \"\"\"\n",
    "    values = line.split(',')\n",
    "    values = [0 if e == '' else int(e) for e in values]\n",
    "    return LabeledPoint(int(values[0]), values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,188,255,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,250,253,93,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,248,253,167,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,247,253,208,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,207,253,235,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,209,253,253,88,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,93,254,253,238,170,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,210,254,253,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,209,253,254,240,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,253,253,254,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,206,254,254,198,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,168,253,253,196,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,203,253,248,76,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,188,253,245,93,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,103,253,253,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,240,253,195,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,220,253,253,80,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,94,253,253,253,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,251,253,250,131,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,214,218,95,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"
     ]
    }
   ],
   "source": [
    "#skip header\n",
    "header = mnist_train.first() #extract header\n",
    "mnist_train = mnist_train.filter(lambda x:x !=header) #filter out header\n",
    "\n",
    "print mnist_train.first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test set - much better to test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeledPoints = mnist_train.map(parsePoint)\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = labeledPoints.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time --- 21.2118899822 seconds ---\n"
     ]
    }
   ],
   "source": [
    "depthLevel = 4\n",
    "treeLevel = 3\n",
    "#start timer\n",
    "start_time = time.time()\n",
    "\n",
    "model = RandomForest.trainClassifier(trainingData, numClasses=10, categoricalFeaturesInfo={},\n",
    "                                             numTrees=treeLevel, featureSubsetStrategy=\"auto\",\n",
    "                                             impurity='gini', maxDepth=depthLevel, maxBins=32)  \n",
    "\n",
    "print(\"Training time --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.452333990796\n",
      "Prediction time --- 6.6730120182 seconds ---\n",
      "Learned classification tree model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 511 <= 1.0)\n",
      "     If (feature 350 <= 132.0)\n",
      "      If (feature 542 <= 0.0)\n",
      "       If (feature 402 <= 0.0)\n",
      "        Predict: 7.0\n",
      "       Else (feature 402 > 0.0)\n",
      "        Predict: 9.0\n",
      "      Else (feature 542 > 0.0)\n",
      "       If (feature 216 <= 0.0)\n",
      "        Predict: 6.0\n",
      "       Else (feature 216 > 0.0)\n",
      "        Predict: 8.0\n",
      "     Else (feature 350 > 132.0)\n",
      "      If (feature 515 <= 1.0)\n",
      "       If (feature 597 <= 9.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 597 > 9.0)\n",
      "        Predict: 3.0\n",
      "      Else (feature 515 > 1.0)\n",
      "       If (feature 375 <= 15.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 375 > 15.0)\n",
      "        Predict: 8.0\n",
      "    Else (feature 511 > 1.0)\n",
      "     If (feature 385 <= 14.0)\n",
      "      If (feature 318 <= 5.0)\n",
      "       If (feature 630 <= 154.0)\n",
      "        Predict: 2.0\n",
      "       Else (feature 630 > 154.0)\n",
      "        Predict: 3.0\n",
      "      Else (feature 318 > 5.0)\n",
      "       If (feature 539 <= 55.0)\n",
      "        Predict: 4.0\n",
      "       Else (feature 539 > 55.0)\n",
      "        Predict: 5.0\n",
      "     Else (feature 385 > 14.0)\n",
      "      If (feature 301 <= 0.0)\n",
      "       If (feature 544 <= 177.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 544 > 177.0)\n",
      "        Predict: 6.0\n",
      "      Else (feature 301 > 0.0)\n",
      "       If (feature 629 <= 122.0)\n",
      "        Predict: 2.0\n",
      "       Else (feature 629 > 122.0)\n",
      "        Predict: 0.0\n",
      "  Tree 1:\n",
      "    If (feature 462 <= 3.0)\n",
      "     If (feature 378 <= 0.0)\n",
      "      If (feature 413 <= 4.0)\n",
      "       If (feature 542 <= 0.0)\n",
      "        Predict: 7.0\n",
      "       Else (feature 542 > 0.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 413 > 4.0)\n",
      "       If (feature 464 <= 84.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 464 > 84.0)\n",
      "        Predict: 6.0\n",
      "     Else (feature 378 > 0.0)\n",
      "      If (feature 153 <= 8.0)\n",
      "       If (feature 159 <= 0.0)\n",
      "        Predict: 9.0\n",
      "       Else (feature 159 > 0.0)\n",
      "        Predict: 5.0\n",
      "      Else (feature 153 > 8.0)\n",
      "       If (feature 264 <= 56.0)\n",
      "        Predict: 3.0\n",
      "       Else (feature 264 > 56.0)\n",
      "        Predict: 5.0\n",
      "    Else (feature 462 > 3.0)\n",
      "     If (feature 290 <= 0.0)\n",
      "      If (feature 351 <= 120.0)\n",
      "       If (feature 512 <= 4.0)\n",
      "        Predict: 7.0\n",
      "       Else (feature 512 > 4.0)\n",
      "        Predict: 2.0\n",
      "      Else (feature 351 > 120.0)\n",
      "       If (feature 430 <= 6.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 430 > 6.0)\n",
      "        Predict: 2.0\n",
      "     Else (feature 290 > 0.0)\n",
      "      If (feature 155 <= 0.0)\n",
      "       If (feature 497 <= 17.0)\n",
      "        Predict: 9.0\n",
      "       Else (feature 497 > 17.0)\n",
      "        Predict: 6.0\n",
      "      Else (feature 155 > 0.0)\n",
      "       If (feature 660 <= 0.0)\n",
      "        Predict: 6.0\n",
      "       Else (feature 660 > 0.0)\n",
      "        Predict: 8.0\n",
      "  Tree 2:\n",
      "    If (feature 437 <= 0.0)\n",
      "     If (feature 290 <= 0.0)\n",
      "      If (feature 468 <= 0.0)\n",
      "       If (feature 205 <= 0.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 205 > 0.0)\n",
      "        Predict: 2.0\n",
      "      Else (feature 468 > 0.0)\n",
      "       If (feature 350 <= 198.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 350 > 198.0)\n",
      "        Predict: 3.0\n",
      "     Else (feature 290 > 0.0)\n",
      "      If (feature 462 <= 0.0)\n",
      "       If (feature 351 <= 0.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 351 > 0.0)\n",
      "        Predict: 5.0\n",
      "      Else (feature 462 > 0.0)\n",
      "       If (feature 380 <= 0.0)\n",
      "        Predict: 5.0\n",
      "       Else (feature 380 > 0.0)\n",
      "        Predict: 8.0\n",
      "    Else (feature 437 > 0.0)\n",
      "     If (feature 597 <= 2.0)\n",
      "      If (feature 153 <= 2.0)\n",
      "       If (feature 209 <= 0.0)\n",
      "        Predict: 4.0\n",
      "       Else (feature 209 > 0.0)\n",
      "        Predict: 9.0\n",
      "      Else (feature 153 > 2.0)\n",
      "       If (feature 683 <= 13.0)\n",
      "        Predict: 6.0\n",
      "       Else (feature 683 > 13.0)\n",
      "        Predict: 3.0\n",
      "     Else (feature 597 > 2.0)\n",
      "      If (feature 658 <= 0.0)\n",
      "       If (feature 124 <= 41.0)\n",
      "        Predict: 2.0\n",
      "       Else (feature 124 > 41.0)\n",
      "        Predict: 2.0\n",
      "      Else (feature 658 > 0.0)\n",
      "       If (feature 318 <= 0.0)\n",
      "        Predict: 3.0\n",
      "       Else (feature 318 > 0.0)\n",
      "        Predict: 8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test instances and compute test error\n",
    "\n",
    "#start timer\n",
    "start_time = time.time()\n",
    "\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "\n",
    "print('Test Error = ' + str(testErr))\n",
    "print(\"Prediction time --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#print('Learned classification tree model:')\n",
    "#print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform grid search over parameters to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\maxDepth = 4.0, trees = 3.0: trainErr = 0.41749\n",
      "Prediction time --- 15.9577219486 seconds ---\n",
      "\\maxDepth = 4.0, trees = 4.0: trainErr = 0.41683\n",
      "Prediction time --- 14.4539039135 seconds ---\n",
      "\\maxDepth = 4.0, trees = 5.0: trainErr = 0.38067\n",
      "Prediction time --- 14.2586538792 seconds ---\n",
      "\\maxDepth = 4.0, trees = 6.0: trainErr = 0.37278\n",
      "Prediction time --- 14.1658930779 seconds ---\n",
      "\\maxDepth = 4.0, trees = 7.0: trainErr = 0.31755\n",
      "Prediction time --- 14.6696748734 seconds ---\n",
      "\\maxDepth = 4.0, trees = 8.0: trainErr = 0.32347\n",
      "Prediction time --- 14.2442209721 seconds ---\n",
      "\\maxDepth = 4.0, trees = 9.0: trainErr = 0.33662\n",
      "Prediction time --- 14.6478559971 seconds ---\n",
      "\\maxDepth = 5.0, trees = 3.0: trainErr = 0.40763\n",
      "Prediction time --- 14.5690767765 seconds ---\n",
      "\\maxDepth = 5.0, trees = 4.0: trainErr = 0.30769\n",
      "Prediction time --- 14.6435680389 seconds ---\n",
      "\\maxDepth = 5.0, trees = 5.0: trainErr = 0.31098"
     ]
    }
   ],
   "source": [
    "bestModel = None\n",
    "bestTestErr = 100\n",
    "\n",
    "maxDepths = range(4,10)\n",
    "maxTrees = range(3,10)\n",
    "for depthLevel in maxDepths:\n",
    "    for treeLevel in maxTrees:\n",
    "        \n",
    "        #start timer\n",
    "        start_time = time.time()\n",
    "        model = RandomForest.trainClassifier(trainingData, numClasses=10, categoricalFeaturesInfo={},\n",
    "                                             numTrees=treeLevel, featureSubsetStrategy=\"auto\",\n",
    "                                             impurity='gini', maxDepth=depthLevel, maxBins=32)        \n",
    "\n",
    "        predictions = model.predict(testData.map(lambda x: x.features))\n",
    "        labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "        testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "        \n",
    "        print ('\\maxDepth = {0:.1f}, trees = {1:.1f}: trainErr = {2:.5f}'\n",
    "               .format(depthLevel, treeLevel, testErr))\n",
    "        print(\"Prediction time --- %s seconds ---\" % (time.time() - start_time))\n",
    "        if (testErr < bestTestErr):\n",
    "            bestModel = model\n",
    "            bestTestErr = testErr\n",
    "            \n",
    "print ('Best Test Error: = {0:.3f}\\n'\n",
    "       .format(bestTestErr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'892,3,\"Kelly, Mr. James\",male,34.5,0,0,330911,7.8292,,Q', u'893,3,\"Wilkes, Mrs. James (Ellen Needs)\",female,47,1,0,363272,7,,S']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "def parseTestPoint(line):\n",
    "    \"\"\"\n",
    "    Parse a line of text into an MLlib LabeledPoint object.\n",
    "    \"\"\"\n",
    "    values = line.split(',')\n",
    "    values = [0 if e == '' else e for e in values]\n",
    "    gender = abs(hash(values[4]))\n",
    "    embarked = abs(hash(values[11]))\n",
    "    return Vectors.dense([float(values[1]),gender,float(values[5]),float(values[6]),float(values[7]),float(values[9]),embarked])\n",
    "\n",
    "fileNameTest = 'wasb://kaggle@criteo.blob.core.windows.net/test.csv'\n",
    "testPoints = sc.textFile(fileNameTest)\n",
    "\n",
    "#skip header\n",
    "headerTest = testPoints.first() #extract header\n",
    "testPoints = testPoints.filter(lambda x:x !=headerTest) #filter out header\n",
    "print testPoints.take(2)\n",
    "\n",
    "testPoints = testPoints.map(parseTestPoint)\n",
    "\n",
    "predictions = model.predict(testPoints)\n",
    "print predictions.take(125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for creating a submission file for kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'892', u'893', u'894']\n"
     ]
    }
   ],
   "source": [
    "#write out predictions to .CSV file\n",
    "submissionIds = sc.textFile(fileNameTest).map(lambda x: x.split(',')[0])\n",
    "\n",
    "#skip header\n",
    "headerSubmission = submissionIds.first() #extract header\n",
    "submissionIds = submissionIds.filter(lambda x:x !=headerSubmission) #filter out header\n",
    "print submissionIds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = submissionIds.zip(predictions.map(lambda x: int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.map(lambda a: str(a[0]) + \",\" + str(a[1])).coalesce(1,True).saveAsTextFile('wasb://criteo@criteo.blob.core.windows.net/kaggle/svcc_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
